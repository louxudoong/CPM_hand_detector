{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_pdprams(pdparms_path, model):\n",
    "\n",
    "    pdparams = {}\n",
    "    with open(pdparms_path, \"r\") as fp:\n",
    "        pdparams = dict(json.load(fp))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            # 跳过不需要加载的参数\n",
    "            if name not in pdparams:\n",
    "                continue\n",
    "            # 将权重从字典 pdparams 中加载到模型中\n",
    "            param.copy_(torch.from_numpy(np.array(pdparams[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "    \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from models import cpm_bn_hand\n",
    "\n",
    "model = cpm_bn_hand.CPM_hand_torch(21).to(device)\n",
    "\n",
    "pdprams_path = \"./bn_500.json\"\n",
    "\n",
    "get_pdprams(pdprams_path, model)\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./aa.jpg\")\n",
    "\n",
    "import thirdparty.mytools as mytools\n",
    "import thirdparty.mytransform as mytransform\n",
    "\n",
    "size_w = img.shape[1]\n",
    "size_h = img.shape[0]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "      # img = cv2.imread(\"./aa.jpg\")\n",
    "      img = cv2.imread(\"./myhand.jpg\")\n",
    "      img = cv2.resize(img, (368, 368))\n",
    "      import copy\n",
    "      img0 = copy.deepcopy(img)\n",
    "      img = np.transpose(img, (2, 0 ,1))\n",
    "\n",
    "      img = img.astype(np.float32)\n",
    "      img = torch.from_numpy(img).unsqueeze(0)  # 添加一个维度以匹配模型的期望输入形状\n",
    "      # centermap = centermap.astype(np.float32)\n",
    "      centermap = mytools.center_map_default(368, 368, 3)\n",
    "      centermap = torch.from_numpy(centermap)\n",
    "      centermap = centermap.unsqueeze(0) # 添加一个维度，变成1 * 1 * H * W\n",
    "      # centermap = torch.nn.functional.interpolate(centermap, size=(size_h, size_w), mode='bilinear', align_corners=False)\n",
    "\n",
    "      \n",
    "      heat1, heat2, heat3, heat4, heat5, heat6 = model(img.to(device), centermap.to(device))\n",
    "      heatmapi = heat6[0].cpu().numpy()\n",
    "      kptsi = mytools.get_kpts_from_heatmap(heatmapi, 368., 368.)\n",
    "      #kptsi_t = get_kpts_from_heatmap(heatmapi_t, 368., 368.)\n",
    "      # kpts_rmse.append(compute_RMSE(heatmapi, heatmapi_t))\n",
    "      import copy\n",
    "      imagei_p = copy.deepcopy(img[0])\n",
    "      imagei_p = np.transpose(imagei_p, (1, 2, 0))\n",
    "      # imagei_t = copy.deepcopy(imagei)\n",
    "      imagei_p = mytools.draw_paint(imagei_p.numpy().copy(), kptsi)\n",
    "      # imagei_t = draw_paint(imagei_t.copy(), kptsi_t)\n",
    "      cv2.imwrite(f'1.jpg', imagei_p)\n",
    "      # cv2.imwrite(f'2.jpg', imagei_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([368, 368, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagei_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = cv2.resize(aa, (368, 368))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368, 368, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/home/louxd/dataset/FreiHand/FreiHAND_pub_v2_eval/evaluation/rgb/00000989.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(\"./aa.jpg\")\n",
    "img = cv2.imread(\"/home/louxd/dataset/FreiHand/FreiHAND_pub_v2_eval/evaluation/rgb/00000989.jpg\")\n",
    "size_w = img.shape[1]\n",
    "size_h = img.shape[0]\n",
    "img = cv2.resize(img, (368, 368))\n",
    "import copy\n",
    "img0 = copy.deepcopy(img)\n",
    "\n",
    "img = np.transpose(img, (2, 0 ,1))\n",
    "\n",
    "img = img.astype(np.float32)\n",
    "img = torch.from_numpy(img).unsqueeze(0)  # 添加一个维度以匹配模型的期望输入形状\n",
    "# centermap = centermap.astype(np.float32)\n",
    "centermap = mytools.center_map_default(size_w, size_h, 3)\n",
    "centermap = torch.from_numpy(centermap)\n",
    "centermap = centermap.unsqueeze(0) # 添加一个维度，变成1 * 1 * H * W\n",
    "# centermap = torch.nn.functional.interpolate(centermap, size=(size_h, size_w), mode='bilinear', align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 368, 368])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 224])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centermap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from models import cpm_bn_hand\n",
    "import thirdparty.mytools as mytools\n",
    "import thirdparty.mytransform as mytransform\n",
    "import socket\n",
    "import argparse\n",
    "import copy\n",
    "\n",
    "\n",
    "def get_pdprams(pdparms_path, model):\n",
    "\n",
    "    pdparams = {}\n",
    "    with open(pdparms_path, \"r\") as fp:\n",
    "        pdparams = dict(json.load(fp))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            # 跳过不需要加载的参数\n",
    "            if name not in pdparams:\n",
    "                continue\n",
    "            # 将权重从字典 pdparams 中加载到模型中\n",
    "            param.copy_(torch.from_numpy(np.array(pdparams[name])))\n",
    "\n",
    "def load_model():\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = cpm_bn_hand.CPM_hand_torch(21).to(device)\n",
    "    pdprams_path = \"./bn_500.json\"\n",
    "    get_pdprams(pdprams_path, model)\n",
    "    return model, device\n",
    "\n",
    "def process_frame(frame, centermap, model, device):\n",
    "\n",
    "    centermap = copy.deepcopy(mytransform.to_tensor(centermap))\n",
    "    centermap = centermap.unsqueeze(0) # 添加一个维度，变成1 * 1 * H * W\n",
    "\n",
    "    img = cv2.resize(frame, (368, 368))\n",
    "    img = copy.deepcopy(mytransform.normalize(mytransform.to_tensor(img), np.array([0.5, 0.5, 0.5])*255,\n",
    "                                np.array([1, 1, 1])*255))\n",
    "    # img = np.transpose(img, (2, 0 ,1))\n",
    "    # img = img.astype(np.float32)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        heat1, heat2, heat3, heat4, heat5, heat6 = model(img.to(device), centermap.to(device))\n",
    "        heatmapi = heat6[0].cpu().numpy()\n",
    "        kptsi = mytools.get_kpts_from_heatmap(heatmapi, 368., 368.)\n",
    "        img0 = np.transpose(img[0], (1, 2, 0)).numpy()\n",
    "        img0 = img0 * np.array([0.229, 0.224, 0.225], dtype=np.float32)*255 + np.array([0.485, 0.456, 0.406], dtype=np.float32)*255\n",
    "        imagei_p = mytools.draw_paint(img0.copy(), kptsi)\n",
    "\n",
    "    return imagei_p\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    model, device = load_model()\n",
    "\n",
    "    # 创建TCP套接字\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "    # WSL虚拟机的IP地址和端口号\n",
    "    wsl_address = (args.wsl_ip, args.port)\n",
    "    print(f\"ip={args.wsl_ip}, port={args.port}\")\n",
    "\n",
    "    try:\n",
    "        sock.bind(wsl_address)\n",
    "        print(\"connect success.\")\n",
    "        BUFFER_SIZE = 655070  # 数据包大小限制\n",
    "\n",
    "        # 设置了以图像中心为gauss核的centermap\n",
    "        centermap = mytools.center_map_default(368, 368, 3)\n",
    "        # centermap = torch.from_numpy(centermap)\n",
    "        # centermap = centermap.unsqueeze(0) # 添加一个维度，变成1 * 1 * H * W\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        while True:\n",
    "            # 接收数据\n",
    "            data, _ = sock.recvfrom(BUFFER_SIZE)\n",
    "            # print(\"Received:\", len(data), \"bytes\")\n",
    "            try:\n",
    "                frame = cv2.imdecode(np.frombuffer(data, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                cv2.imshow('frame', frame)\n",
    "                imagei_p = process_frame(frame, centermap, model, device)\n",
    "                print(imagei_p.shape)\n",
    "                # 在WSL中显示图像\n",
    "                cv2.imshow('process img', imagei_p)\n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(\"Error decoding image:\", e)\n",
    "\n",
    "            count += 1\n",
    "            if (count % 100) == 0:\n",
    "                cv2.imwrite(f'./output/{count}.jpg', imagei_p)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    finally:\n",
    "        # 关闭套接字和窗口\n",
    "        sock.close()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"./aa.jpg\")\n",
    "\n",
    "model, device = load_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "centermap = mytools.center_map_default(368, 368, 3)\n",
    "# centermap = copy.deepcopy(mytransform.to_tensor(centermap))\n",
    "centermap = torch.from_numpy(centermap).unsqueeze(0) # 添加一个维度，变成1 * 1 * H * W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 368, 368])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centermap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img = cv2.resize(frame, (368, 368))\n",
    "img = copy.deepcopy(mytransform.normalize(mytransform.to_tensor(img), np.array([0.5, 0.5, 0.5])*255,\n",
    "                            np.array([1, 1, 1])*255))\n",
    "# img = np.transpose(img, (2, 0 ,1))\n",
    "# img = img.astype(np.float32)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    heat1, heat2, heat3, heat4, heat5, heat6 = model(img.to(device), centermap.to(device))\n",
    "    heatmapi = heat6[0].cpu().numpy()\n",
    "    kptsi = mytools.get_kpts_from_heatmap(heatmapi, 368., 368.)\n",
    "    img0 = np.transpose(img[0], (1, 2, 0)).numpy()\n",
    "    img0 = img0 * np.array([0.229, 0.224, 0.225], dtype=np.float32)*255 + np.array([0.485, 0.456, 0.406], dtype=np.float32)*255\n",
    "    imagei_p = mytools.draw_paint(img0.copy(), kptsi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368, 368, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagei_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"1111.jpg\", imagei_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
